{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2243b1-1b7e-4457-99a0-f80e8b6411f3",
   "metadata": {},
   "source": [
    "The goal is to get all the Retail (17000 category) venues from FourSquare Places for Greater Brisbane and remove all duplicates from the results. \n",
    "Entry points must be taken from GeoJSON file. The GeoJSON file contains a grid of points in Greater Brisbane. The task involves sending requests using FourSquare Places API for each point. The points are 6 km apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ac5860-7f5c-4d79-86e5-2dbffd1eb88a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q google-cloud google-cloud-storage google-cloud-bigquery geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d86f1982-a3cc-407a-b1ba-b6a015530e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from geopy.distance import geodesic\n",
    "from tqdm import tqdm\n",
    "\n",
    "fsq_authorization_key = \"*\" # Set `fsq_authorization_key` to authorization key\n",
    "credentials_path = r\"C:\\Users\\*\\*\\*.json\" # Set `credentials_path` to local path to JSON file with credentials\n",
    "points_table_id = \"teak-surge-408913.geo.Greater Brisbane Grid 6km\"\n",
    "credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "client = bigquery.Client(credentials=credentials)\n",
    "export_table_id_prefix = \"teak-surge-408913.geo.fsq_venues_export\"\n",
    "search_category = 17000\n",
    "\n",
    "# We have the condition that the points are six kilometers apart, sitting on an imaginary grid. \n",
    "# So the distance between the nearest points that are not on the same square side is the diagonal of that square, \n",
    "# which divides it into two right triangles. The hypotenuse of these triangles (=the diagonal of the square) \n",
    "# is approximately 8485.28137. If we take a half-point search radius, we cover the entire space between the points. \n",
    "# 4243 is rounded value of the 8485.28137/2.\n",
    "search_radius = 4243"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e23051a-7113-402f-b6cb-989ef4e2678a",
   "metadata": {},
   "source": [
    "Collect all point coordinates from `Greater Brisbane Grid 6km` located in the BigQuery Studio project using BigQuery's client and save them into Python dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3824f62c-e287-48db-a1dc-82aa79a1cbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    longitude   latitude  point_id\n",
      "0  151.820446 -27.531805        77\n",
      "1  151.820446 -27.579590        78\n",
      "2  151.820446 -27.627354        79\n",
      "3  151.820446 -27.675097        80\n",
      "4  151.820446 -27.722819        81\n"
     ]
    }
   ],
   "source": [
    "get_coordinates_query = f'''SELECT geometry.coordinates[0] AS longitude, \n",
    "geometry.coordinates[1] AS latitude, \n",
    "properties.id AS point_id \n",
    "FROM `{points_table_id}`'''\n",
    "point_coordinates = client.query(get_coordinates_query).to_dataframe()\n",
    "print(point_coordinates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ceaf4-1185-4e88-b9e1-7766bca09cd0",
   "metadata": {},
   "source": [
    "Send an API request for venues in `Retail(17000)` category within search radius of `4243` from the point coordinates to the foursquare's server, remove duplicates and export obtained list of venues to a BigQuery Studio project's table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e4f2c6-aa94-46f8-83a3-45f37bb62747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 813/813 [11:13<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venues found total: 6295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# foursquare request's data\n",
    "url = \"https://api.foursquare.com/v3/places/search\"\n",
    "params = {\n",
    "    \"ll\": \"\",\n",
    "    \"categories\": f\"{search_category}\",\n",
    "    \"radius\": f\"{search_radius}\"\n",
    "}\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Authorization\": f\"{fsq_authorization_key}\"\n",
    "}\n",
    "\n",
    "# Function to extract the URL from the link\n",
    "def extract_next_link(link_header):\n",
    "    links = link_header.split(', ')\n",
    "    for link in links:\n",
    "        url, rel = link.split('; ')\n",
    "        if 'rel=\"next\"' in rel:\n",
    "            return url.strip('<>')\n",
    "\n",
    "def get_fsq_page_recursive(url, params, headers):\n",
    "    response = requests.request(\"GET\", url, params=params, headers=headers)\n",
    "    resp_headers = response.headers\n",
    "    responce_dict = json.loads(response.text)\n",
    "    venues = responce_dict[\"results\"] #list of venues from responce\n",
    "    #print(resp_headers)\n",
    "    if 'Link' not in resp_headers.keys():\n",
    "        return venues\n",
    "    \n",
    "    next_page = extract_next_link(resp_headers[\"Link\"])\n",
    "    #print(f\"Next-Page: {next_page}\")\n",
    "    \n",
    "    # we don't need to add parameters they are already in the URL\n",
    "    v = get_fsq_page_recursive(next_page, [], headers)\n",
    "    venues.extend(v)\n",
    "    return venues\n",
    "\n",
    "# find all venues for the points from `Greater Brisbane Grid 6km` and add it to dataframe\n",
    "found_venues = []\n",
    "for _, point in tqdm(point_coordinates.iterrows(), total=point_coordinates.shape[0]):\n",
    "    params[\"ll\"] = f\"{point[1]},{point[0]}\"\n",
    "    venues = get_fsq_page_recursive(url, params=params, headers=headers)\n",
    "    for fsq in venues:\n",
    "        try:         \n",
    "            entity = dict()\n",
    "            entity[\"fsq_id\"] = fsq[\"fsq_id\"]\n",
    "            entity[\"point_id\"] = f\"{point[2]}\" \n",
    "            entity[\"latitude\"] = fsq[\"geocodes\"][\"main\"][\"latitude\"]\n",
    "            entity[\"longitude\"] = fsq[\"geocodes\"][\"main\"][\"longitude\"]\n",
    "            entity[\"address\"] = fsq.get(\"location\", {}).get(\"address\", None) \n",
    "            entity[\"country\"] = fsq.get(\"location\", {}).get(\"country\", None)\n",
    "            entity[\"cross_street\"] = fsq.get(\"location\", {}).get(\"cross_street\", None)\n",
    "            entity[\"formatted_address\"] = fsq.get(\"location\", {}).get(\"formatted_address\", None)\n",
    "            entity[\"locality\"] = fsq.get(\"location\", {}).get(\"locality\", None)\n",
    "            entity[\"postcode\"] = fsq.get(\"location\", {}).get(\"postcode\", None)\n",
    "            entity[\"region\"] = fsq.get(\"location\", {}).get(\"region\", None)\n",
    "            entity[\"name\"] = fsq.get(\"name\", None)\n",
    "            entity[\"dist\"] = geodesic((point[1],point[0]), (entity[\"latitude\"],entity[\"longitude\"])).km\n",
    "            found_venues.append(entity)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "print(f\"Venues found total: {len(found_venues)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12174f33-4578-404c-aa86-ef0b122687de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new table: teak-surge-408913.geo.fsq_venues_export_20231228132038\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "# specify schema for a table with exported data from foursquare\n",
    "schema=[\n",
    "    bigquery.SchemaField(\"fsq_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"point_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"latitude\", \"FLOAT64\"),\n",
    "    bigquery.SchemaField(\"longitude\", \"FLOAT64\"),\n",
    "    bigquery.SchemaField(\"address\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"country\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"cross_street\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"formatted_address\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"locality\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"postcode\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"region\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"name\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"dist\", \"FLOAT64\"),\n",
    "    ]\n",
    "\n",
    "#create new table \n",
    "table_id = f'''{export_table_id_prefix}_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'''\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "table = client.create_table(table)\n",
    "\n",
    "print(f\"Created new table: {table_id}\")\n",
    "\n",
    "errors = client.insert_rows_json(table, found_venues)\n",
    "if errors == []:\n",
    "    print(\"success\")\n",
    "else:\n",
    "    for error in errors:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566231cf-4bd8-4ef3-930d-e54459801308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryJob<project=teak-surge-408913, location=US, id=100588f9-18dc-40b2-a126-699216061e5e>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_duplicates_query = f'''CREATE OR REPLACE TABLE `{table_id}` AS (\n",
    "  SELECT * EXCEPT(row_num) FROM (\n",
    "      SELECT *,\n",
    "        ROW_NUMBER() OVER (\n",
    "        PARTITION BY\n",
    "        fsq_id\n",
    "        ORDER BY\n",
    "        dist ASC\n",
    "        ) row_num\n",
    "      FROM\n",
    "      `{table_id}`)\n",
    "  WHERE row_num=1\n",
    ")'''\n",
    "client.query(clean_duplicates_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678b0ef-7531-443d-b7dd-e44169a86d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
